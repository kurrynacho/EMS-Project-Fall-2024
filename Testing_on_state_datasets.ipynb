{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on States\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import importlib\n",
    "from seaborn import set_style\n",
    "set_style=(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\G'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\G'\n",
      "C:\\Users\\jessi\\AppData\\Local\\Temp\\ipykernel_43276\\2844415249.py:1: SyntaxWarning: invalid escape sequence '\\G'\n",
      "  df = pd.read_csv(\"D:\\Graduate Center Dropbox\\Yuan Liu\\Data Science Project\\data\\destination_State_d_2018.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:\\Graduate Center Dropbox\\Yuan Liu\\Data Science Project\\data\\destination_State_d_2018.csv\")\n",
    "unique_states = df['Masked_DestinationState'].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation. \n",
    "Preprocessing the state data sets. This takes about 100 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import preprocessing\n",
    "statedict={}\n",
    "scalerdict = {}\n",
    "rowsdict = {}\n",
    "for state in unique_states:\n",
    "    try:\n",
    "        L=[]\n",
    "        S=[]\n",
    "        rowsdict[state]=0\n",
    "        for i in range(2018,2023): #adjust here when we get more years of data\n",
    "            if not os.path.exists('D:/Graduate Center Dropbox/Yuan Liu/Data Science Project/parquetfiles/'+str(i)+'states/state_'+state+'.parquet'):\n",
    "                raise FileNotFoundError(f\"{state} not found\")\n",
    "            else:\n",
    "                df=pd.read_parquet('D:/Graduate Center Dropbox/Yuan Liu/Data Science Project/parquetfiles/'+str(i)+'states/state_'+state+'.parquet')\n",
    "                data, scaler=preprocessing.get_processed_series(df)\n",
    "                L.append(data)\n",
    "                S.append(scaler)\n",
    "                rowsdict[state]=rowsdict[state]+df.shape[0]\n",
    "        scalerdict[state]=S\n",
    "        statedict[state]=pd.concat(L, ignore_index=True)\n",
    "        print(state)\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in statedict:\n",
    "    statedict[state].to_csv('state_timeseries/' +state+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation:\n",
    "Earlier testing had shown that for the state datasets, the best performing model was usually arima or some combination of another model and arima. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results for some states. 5-fold test-train split and 14 day horizon: \n",
    "| Model                              | MSE      | MAE      | NMSE     |\n",
    "|------------------------------------|----------|----------|----------|\n",
    "| arima                              | 0.007985 | 0.069237 | 0.145986 |\n",
    "| smoothing_arima_mult_60            | 0.011781 | 0.083090 | 0.215386 |\n",
    "| expsmoothing_predict               | 0.026719 | 0.135345 | 0.488499 |\n",
    "| prophet_arima_mult_60              | 0.043296 | 0.193694 | 0.791573 |\n",
    "| constant_predict                   | 0.045169 | 0.185501 | 0.825808 |\n",
    "| prophet_arima_withlockdown_mult_60 | 0.045963 | 0.200433 | 0.840332 |\n",
    "| naive_predict                      | 0.054696 | 0.207830 | 1.000000 |\n",
    "| prophet_predict                    | 0.066626 | 0.221163 | 1.218112 |\n",
    "| prophet_predict_withlockdown       | 0.071463 | 0.230041 | 1.306538 |\n",
    "\n",
    "---\n",
    "\n",
    "| Model                              | MSE      | MAE      | NMSE     |\n",
    "|------------------------------------|----------|----------|----------|\n",
    "| smoothing_arima_mult_60            | 0.024166 | 0.121657 | 0.243903 |\n",
    "| arima                              | 0.025288 | 0.124166 | 0.255231 |\n",
    "| prophet_arima_mult_60              | 0.030775 | 0.135252 | 0.310610 |\n",
    "| prophet_predict                    | 0.034370 | 0.145436 | 0.346894 |\n",
    "| prophet_arima_withlockdown_mult_60 | 0.034663 | 0.142469 | 0.349848 |\n",
    "| prophet_predict_withlockdown       | 0.042451 | 0.166660 | 0.428456 |\n",
    "| constant_predict                   | 0.063579 | 0.228481 | 0.641695 |\n",
    "| expsmoothing_predict               | 0.069580 | 0.219339 | 0.702263 |\n",
    "| naive_predict                      | 0.099080 | 0.282994 | 1.000000 |\n",
    "\n",
    "---\n",
    "\n",
    "| Model                              | MSE      | MAE      | NMSE     |\n",
    "|------------------------------------|----------|----------|----------|\n",
    "| smoothing_arima_mult_60            | 0.013612 | 0.086667 | 0.202720 |\n",
    "| prophet_arima_withlockdown_mult_60 | 0.014033 | 0.090110 | 0.208993 |\n",
    "| prophet_arima_mult_60              | 0.014170 | 0.090703 | 0.211026 |\n",
    "| prophet_predict_withlockdown       | 0.015100 | 0.086135 | 0.224886 |\n",
    "| arima                              | 0.015156 | 0.092909 | 0.225717 |\n",
    "| prophet_predict                    | 0.016409 | 0.094101 | 0.244378 |\n",
    "| expsmoothing_predict               | 0.050661 | 0.180158 | 0.754489 |\n",
    "| constant_predict                   | 0.066803 | 0.235438 | 0.994884 |\n",
    "| naive_predict                      | 0.067146 | 0.232929 | 1.000000 |\n",
    "\n",
    "---\n",
    "\n",
    "| Model                              | MSE      | MAE      | NMSE     |\n",
    "|------------------------------------|----------|----------|----------|\n",
    "| arima                              | 0.009272 | 0.067246 | 0.120145 |\n",
    "| smoothing_arima_mult_60            | 0.009972 | 0.070253 | 0.129212 |\n",
    "| prophet_arima_withlockdown_mult_60 | 0.016693 | 0.101468 | 0.216302 |\n",
    "| prophet_arima_mult_60              | 0.021541 | 0.118026 | 0.279119 |\n",
    "| prophet_predict_withlockdown       | 0.036426 | 0.176712 | 0.471995 |\n",
    "| prophet_predict                    | 0.042576 | 0.194689 | 0.551677 |\n",
    "| constant_predict                   | 0.056545 | 0.187477 | 0.732683 |\n",
    "| expsmoothing_predict               | 0.057328 | 0.186379 | 0.742821 |\n",
    "| naive_predict                      | 0.077176 | 0.253326 | 1.000000 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_states = dict(sorted(rowsdict.items(), key=lambda item: item[1], reverse=True))\n",
    "largest_list=list(largest_states.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import forecasting\n",
    "from itertools import islice\n",
    "params = {\n",
    "    'type': ['mult'],\n",
    "    'window': [180]\n",
    "}\n",
    "results_dict={}\n",
    "for state in largest_list[:5]:\n",
    "    print(state)\n",
    "    if state in statedict:\n",
    "        results_dict[state]=forecasting.ttsplit_predictions(statedict[state], 5, 14, extra_models=[], printprogress=True, do_arima=True, smoothing_params=params, fixed_residue_models=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Model       MSE       MAE      NMSE\n",
      "3             smoothing_arima_mult_180  0.007861  0.070061  0.143725\n",
      "4               prophet_arima_mult_180  0.007871  0.069551  0.143912\n",
      "0                                arima  0.007985  0.069237  0.145986\n",
      "5  prophet_arima_withlockdown_mult_180  0.009354  0.076441  0.171012\n",
      "2                     constant_predict  0.045169  0.185501  0.825808\n",
      "1                        naive_predict  0.054696  0.207830  1.000000\n",
      "                                 Model       MSE       MAE      NMSE\n",
      "4               prophet_arima_mult_180  0.025648  0.104347  0.213916\n",
      "5  prophet_arima_withlockdown_mult_180  0.025719  0.104933  0.214502\n",
      "3             smoothing_arima_mult_180  0.026052  0.105167  0.217283\n",
      "0                                arima  0.028443  0.108505  0.237226\n",
      "2                     constant_predict  0.073849  0.245204  0.615923\n",
      "1                        naive_predict  0.119899  0.315722  1.000000\n",
      "                                 Model       MSE       MAE      NMSE\n",
      "3             smoothing_arima_mult_180  0.022148  0.114445  0.223540\n",
      "4               prophet_arima_mult_180  0.022168  0.114233  0.223740\n",
      "5  prophet_arima_withlockdown_mult_180  0.022399  0.115304  0.226073\n",
      "0                                arima  0.025288  0.124166  0.255231\n",
      "2                     constant_predict  0.063579  0.228481  0.641695\n",
      "1                        naive_predict  0.099080  0.282994  1.000000\n",
      "                                 Model       MSE       MAE      NMSE\n",
      "0                                arima  0.009272  0.067246  0.120145\n",
      "5  prophet_arima_withlockdown_mult_180  0.009457  0.070602  0.122539\n",
      "4               prophet_arima_mult_180  0.009472  0.070735  0.122734\n",
      "3             smoothing_arima_mult_180  0.009782  0.069766  0.126750\n",
      "2                     constant_predict  0.056545  0.187477  0.732683\n",
      "1                        naive_predict  0.077176  0.253326  1.000000\n",
      "                                 Model       MSE       MAE      NMSE\n",
      "5  prophet_arima_withlockdown_mult_180  0.026331  0.115994  0.316101\n",
      "4               prophet_arima_mult_180  0.026372  0.116460  0.316590\n",
      "3             smoothing_arima_mult_180  0.026392  0.115871  0.316830\n",
      "0                                arima  0.027498  0.120784  0.330104\n",
      "2                     constant_predict  0.056221  0.211290  0.674913\n",
      "1                        naive_predict  0.083301  0.219414  1.000000\n"
     ]
    }
   ],
   "source": [
    "from forecasting import holdout_values\n",
    "for state in results_dict:\n",
    "    print(forecasting.evaluate_predictions(holdout_values(statedict[state].fillna(0), 5,14), results_dict[state]).sort_values(by='NMSE'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import dask.dataframe as dd\n",
    "test_dict = {}\n",
    "for state in largest_states:\n",
    "    if os.path.exists('../parquetfiles/2023states/state_'+state+'.parquet'):\n",
    "        df=dd.read_parquet('../parquetfiles/2023states/state_'+state+'.parquet')\n",
    "        test_dict[state]=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import loadingdata\n",
    "for state in test_dict:\n",
    "    test_dict[state]=loadingdata.filtered_df(test_dict[state], ['eTimes_03'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing\n",
    "importlib.reload(preprocessing)\n",
    "test_series={}\n",
    "test_scalers={}\n",
    "for state in test_dict:\n",
    "    test_series[state], test_scalers[state]=preprocessing.get_processed_series(test_dict[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dict={}\n",
    "for state in largest_states:\n",
    "    if state in statedict and state in test_dict:\n",
    "        total_dict[state]=pd.concat([statedict[state], test_dict[state]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import forecasting\n",
    "importlib.reload(forecasting)\n",
    "params = {\n",
    "    'type': ['mult'],\n",
    "    'window': [120]\n",
    "}\n",
    "\n",
    "final_dict2={}\n",
    "for county in total_dict:\n",
    "    print(county)\n",
    "    final_dict2[county]=forecasting.ttsplit_predictions(total_dict[county], 10, 14, fixed_residue_models=True,smoothing_params=params, printprogress=False, do_arima=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GG20J\n",
      "                                 Model           MSE         MAE      NMSE\n",
      "5  prophet_arima_withlockdown_mult_120  2.000064e+05  329.198209  0.159648\n",
      "3             smoothing_arima_mult_120  1.998163e+05  334.779607  0.159496\n",
      "0                                arima  2.355673e+05  347.358173  0.188033\n",
      "4               prophet_arima_mult_120  2.186270e+05  348.695276  0.174511\n",
      "2                     constant_predict  3.855355e+05  495.712774  0.307740\n",
      "1                        naive_predict  1.252795e+06  979.400394  1.000000\n",
      "AO6O4\n",
      "                                 Model            MSE         MAE      NMSE\n",
      "5  prophet_arima_withlockdown_mult_120  164246.126316  244.735054  0.194815\n",
      "4               prophet_arima_mult_120  164316.292349  245.102250  0.194898\n",
      "3             smoothing_arima_mult_120  163913.673383  245.634838  0.194421\n",
      "0                                arima  169831.032729  258.231570  0.201439\n",
      "2                     constant_predict  532236.182190  584.996918  0.631294\n",
      "1                        naive_predict  843088.288559  708.933539  1.000000\n",
      "BPU94\n",
      "                                 Model            MSE         MAE      NMSE\n",
      "3             smoothing_arima_mult_120  131270.141644  265.471256  0.229005\n",
      "0                                arima  135882.716479  275.530808  0.237051\n",
      "4               prophet_arima_mult_120  152504.353823  296.116275  0.266048\n",
      "5  prophet_arima_withlockdown_mult_120  162867.949162  309.408428  0.284128\n",
      "2                     constant_predict  290889.123617  434.810642  0.507465\n",
      "1                        naive_predict  573220.464286  662.192857  1.000000\n",
      "OE6XL\n",
      "                                 Model           MSE          MAE      NMSE\n",
      "0                                arima  1.563002e+05   231.883649  0.041965\n",
      "4               prophet_arima_mult_120  1.681518e+05   248.142640  0.045147\n",
      "5  prophet_arima_withlockdown_mult_120  1.687173e+05   249.649700  0.045299\n",
      "3             smoothing_arima_mult_120  1.741958e+05   258.873320  0.046770\n",
      "2                     constant_predict  7.858871e+05   773.193714  0.211002\n",
      "1                        naive_predict  3.724550e+06  1757.507143  1.000000\n",
      "1ZA3P\n",
      "                                 Model            MSE         MAE      NMSE\n",
      "0                                arima  210390.043063  269.270525  0.309404\n",
      "3             smoothing_arima_mult_120  212435.270164  280.280644  0.312411\n",
      "5  prophet_arima_withlockdown_mult_120  240307.460193  289.970374  0.353401\n",
      "4               prophet_arima_mult_120  241547.682566  291.206911  0.355225\n",
      "2                     constant_predict  461645.532694  551.674573  0.678905\n",
      "1                        naive_predict  679985.612029  708.055702  1.000000\n"
     ]
    }
   ],
   "source": [
    "for state in final_dict2:\n",
    "    print(state)\n",
    "    scaler=test_scalers[state]\n",
    "    av=holdout_values(total_dict[state].fillna(0), 10,14).reshape(-1,1)\n",
    "    av=scaler.inverse_transform(av)\n",
    "    preds={}\n",
    "    for model in final_dict2[state]:\n",
    "        preds[model]=scaler.inverse_transform(final_dict2[state][model].reshape(-1,1))\n",
    "\n",
    "    print(forecasting.evaluate_predictions(av, preds).sort_values(by='MAE'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prophet arima performs much better at the state level than at the county level. This may because the increase in datasize makes it possible for a more complicated model to do well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_monthly={}\n",
    "for state in total_dict:\n",
    "    total_monthly[state]=preprocessing.convert_to_monthly(total_dict[state])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forecasting import expsmoothing_predict, monthly_prophet_predict, monthly_prophet_predict_withlockdown\n",
    "monthly_predictionsdict={}\n",
    "params = {\n",
    "    'type': ['mult'],\n",
    "    'window': [6]\n",
    "}\n",
    "\n",
    "for state in total_monthly:\n",
    "    monthly_predictionsdict[state]=forecasting.ttsplit_predictions(total_monthly[state], 1,12,extra_models=[monthly_prophet_predict_withlockdown, monthly_prophet_predict, expsmoothing_predict], smoothing_params=params, fixed_residue_models=True, residue_window_size=6, monthly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GG20J\n",
      "                                  Model           MSE           MAE       NMSE\n",
      "0                                 arima  7.225390e+07   7213.175074   0.168062\n",
      "2                      constant_predict  7.361833e+07   7281.402224   0.171236\n",
      "6                smoothing_arima_mult_6  2.068546e+08  12911.124765   0.481142\n",
      "4               monthly_prophet_predict  2.703686e+08  13695.688089   0.628875\n",
      "3  monthly_prophet_predict_withlockdown  3.009666e+08  14671.593499   0.700045\n",
      "1                         naive_predict  4.299245e+08  19710.021249   1.000000\n",
      "5                  expsmoothing_predict  8.679547e+08  28875.070633   2.018854\n",
      "8     prophet_arima_withlockdown_mult_6  8.613867e+09  85713.034964  20.035767\n",
      "7                  prophet_arima_mult_6  9.060580e+09  86791.259331  21.074818\n",
      "AO6O4\n",
      "                                  Model           MSE           MAE  \\\n",
      "0                                 arima  4.361848e+07   4832.744391   \n",
      "1                         naive_predict  4.361848e+07   4832.744391   \n",
      "5                  expsmoothing_predict  8.626174e+07   7030.979929   \n",
      "6                smoothing_arima_mult_6  1.047479e+08   8964.230119   \n",
      "2                      constant_predict  1.577854e+08  11171.375689   \n",
      "4               monthly_prophet_predict  2.101084e+08  11360.211624   \n",
      "3  monthly_prophet_predict_withlockdown  2.712297e+08  14041.169765   \n",
      "8     prophet_arima_withlockdown_mult_6  9.237575e+09  79127.775279   \n",
      "7                  prophet_arima_mult_6  1.240284e+10  93243.060634   \n",
      "\n",
      "         NMSE  \n",
      "0    1.000000  \n",
      "1    1.000000  \n",
      "5    1.977642  \n",
      "6    2.401458  \n",
      "2    3.617398  \n",
      "4    4.816960  \n",
      "3    6.218231  \n",
      "8  211.781243  \n",
      "7  284.348256  \n",
      "BPU94\n",
      "                                  Model           MSE           MAE       NMSE\n",
      "0                                 arima  3.683853e+07   4750.698219   0.445756\n",
      "5                  expsmoothing_predict  3.540555e+07   5163.322808   0.428416\n",
      "2                      constant_predict  4.699057e+07   5471.005941   0.568598\n",
      "1                         naive_predict  8.264286e+07   7510.713124   1.000000\n",
      "4               monthly_prophet_predict  1.671126e+08  10466.015955   2.022106\n",
      "3  monthly_prophet_predict_withlockdown  1.766735e+08  10859.456311   2.137795\n",
      "6                smoothing_arima_mult_6  1.712212e+08  11219.040433   2.071820\n",
      "8     prophet_arima_withlockdown_mult_6  3.906775e+08  16496.586529   4.727300\n",
      "7                  prophet_arima_mult_6  1.555673e+09  32176.545736  18.824048\n",
      "OE6XL\n",
      "                                  Model           MSE           MAE       NMSE\n",
      "6                smoothing_arima_mult_6  2.212951e+07   4290.467616   0.588695\n",
      "5                  expsmoothing_predict  2.580332e+07   4345.170043   0.686426\n",
      "1                         naive_predict  3.759082e+07   5358.603765   1.000000\n",
      "2                      constant_predict  5.026762e+07   6092.514842   1.337231\n",
      "0                                 arima  5.092778e+07   6105.230494   1.354793\n",
      "4               monthly_prophet_predict  8.195555e+07   7562.164802   2.180201\n",
      "3  monthly_prophet_predict_withlockdown  1.055795e+08   8631.185361   2.808651\n",
      "8     prophet_arima_withlockdown_mult_6  5.671551e+08  20247.715071  15.087595\n",
      "7                  prophet_arima_mult_6  2.394341e+09  41844.399227  63.694833\n",
      "1ZA3P\n",
      "                                  Model           MSE           MAE      NMSE\n",
      "5                  expsmoothing_predict  9.851192e+07   6448.268325  1.098860\n",
      "1                         naive_predict  8.964923e+07   7106.394948  1.000000\n",
      "4               monthly_prophet_predict  1.136633e+08   7651.557700  1.267868\n",
      "2                      constant_predict  1.013439e+08   8344.956260  1.130450\n",
      "0                                 arima  1.011387e+08   8493.248499  1.128161\n",
      "3  monthly_prophet_predict_withlockdown  1.248244e+08   9074.123963  1.392364\n",
      "8     prophet_arima_withlockdown_mult_6  1.534863e+08  11840.204540  1.712076\n",
      "6                smoothing_arima_mult_6  3.066289e+08  12014.479146  3.420318\n",
      "7                  prophet_arima_mult_6  7.576888e+08  19591.188291  8.451705\n"
     ]
    }
   ],
   "source": [
    "for state in monthly_predictionsdict:\n",
    "    print(state)\n",
    "    scaler=test_scalers[state]\n",
    "    av=holdout_values(total_monthly[state].fillna(0), 1,12).reshape(-1,1)\n",
    "    av=scaler.inverse_transform(av)\n",
    "    preds={}\n",
    "    for model in monthly_predictionsdict[state]:\n",
    "        preds[model]=scaler.inverse_transform(monthly_predictionsdict[state][model].reshape(-1,1))\n",
    "    print(forecasting.evaluate_predictions(av, preds).sort_values(by='MAE'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
